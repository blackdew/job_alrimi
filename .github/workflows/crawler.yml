name: Crawler Automation

on:
  # 30ë¶„ë§ˆë‹¤ ìë™ ì‹¤í–‰
  schedule:
    - cron: '*/30 * * * *'

  # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥
  workflow_dispatch:
    inputs:
      crawl_type:
        description: 'í¬ë¡¤ë§ íƒ€ì…'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - jobs
          - houses

env:
  NODE_VERSION: '20'

jobs:
  crawl:
    runs-on: ubuntu-latest

    defaults:
      run:
        working-directory: crawler

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: crawler/package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install chromium --with-deps

      - name: Setup Firebase credentials
        env:
          FIREBASE_SERVICE_ACCOUNT: ${{ secrets.FIREBASE_SERVICE_ACCOUNT }}
        run: |
          # Base64 ë””ì½”ë”©í•˜ì—¬ ì„œë¹„ìŠ¤ ê³„ì • JSON íŒŒì‹±
          SERVICE_ACCOUNT_JSON=$(echo "$FIREBASE_SERVICE_ACCOUNT" | base64 -d)

          # í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ìƒì„±
          echo "FIREBASE_PROJECT_ID=$(echo $SERVICE_ACCOUNT_JSON | jq -r '.project_id')" >> $GITHUB_ENV
          echo "FIREBASE_CLIENT_EMAIL=$(echo $SERVICE_ACCOUNT_JSON | jq -r '.client_email')" >> $GITHUB_ENV

          # private_keyëŠ” ê°œí–‰ë¬¸ì ì²˜ë¦¬ê°€ í•„ìš”
          PRIVATE_KEY=$(echo $SERVICE_ACCOUNT_JSON | jq -r '.private_key')
          echo "FIREBASE_PRIVATE_KEY<<EOF" >> $GITHUB_ENV
          echo "$PRIVATE_KEY" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV

      - name: Run crawler
        env:
          FIREBASE_PROJECT_ID: ${{ env.FIREBASE_PROJECT_ID }}
          FIREBASE_CLIENT_EMAIL: ${{ env.FIREBASE_CLIENT_EMAIL }}
          FIREBASE_PRIVATE_KEY: ${{ env.FIREBASE_PRIVATE_KEY }}
        run: |
          CRAWL_TYPE="${{ github.event.inputs.crawl_type || 'all' }}"

          case $CRAWL_TYPE in
            jobs)
              echo "ğŸ¢ ì¼ìë¦¬ë§Œ í¬ë¡¤ë§..."
              npm run crawl:jobs
              ;;
            houses)
              echo "ğŸ  ë¹ˆì§‘ë§Œ í¬ë¡¤ë§..."
              npm run crawl:houses
              ;;
            *)
              echo "ğŸ“‹ ì „ì²´ í¬ë¡¤ë§..."
              npm run crawl
              ;;
          esac

      - name: Report success
        if: success()
        run: echo "âœ… í¬ë¡¤ë§ ì™„ë£Œ - $(date '+%Y-%m-%d %H:%M:%S KST')"

  # ì‹¤íŒ¨ ì‹œ Issue ìƒì„±
  create-issue-on-failure:
    runs-on: ubuntu-latest
    needs: crawl
    if: failure()

    permissions:
      issues: write

    steps:
      - name: Create failure issue
        uses: actions/github-script@v7
        with:
          script: |
            const title = `ğŸš¨ í¬ë¡¤ëŸ¬ ì‹¤íŒ¨ - ${new Date().toISOString().split('T')[0]}`;
            const body = `
            ## í¬ë¡¤ëŸ¬ ìë™í™” ì‹¤íŒ¨ ì•Œë¦¼

            **ì‹¤í–‰ ì‹œê°„**: ${new Date().toISOString()}
            **ì›Œí¬í”Œë¡œìš°**: ${context.workflow}
            **ì‹¤í–‰ ë²ˆí˜¸**: #${context.runNumber}

            ### ìƒì„¸ ì •ë³´
            - [ì‹¤í–‰ ë¡œê·¸ í™•ì¸](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})

            ### ì¡°ì¹˜ í•„ìš”
            - [ ] ë¡œê·¸ í™•ì¸ ë° ì˜¤ë¥˜ ì›ì¸ íŒŒì•…
            - [ ] í¬ë¡¤ë§ ëŒ€ìƒ ì‚¬ì´íŠ¸ ì ‘ê·¼ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            - [ ] Firebase ì—°ê²° ìƒíƒœ í™•ì¸
            `;

            // ê¸°ì¡´ ì—´ë¦° ì´ìŠˆê°€ ìˆëŠ”ì§€ í™•ì¸
            const { data: issues } = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'crawler-failure'
            });

            if (issues.length === 0) {
              // ìƒˆ ì´ìŠˆ ìƒì„±
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body,
                labels: ['crawler-failure', 'bug']
              });
              console.log('ìƒˆ ì´ìŠˆê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.');
            } else {
              // ê¸°ì¡´ ì´ìŠˆì— ì½”ë©˜íŠ¸ ì¶”ê°€
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issues[0].number,
                body: `### ì¶”ê°€ ì‹¤íŒ¨ ë°œìƒ\n${body}`
              });
              console.log('ê¸°ì¡´ ì´ìŠˆì— ì½”ë©˜íŠ¸ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.');
            }
